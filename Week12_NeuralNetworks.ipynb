{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBKt1hvIxlmE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.keras as kb\n",
        "from tensorflow.keras import backend\n",
        "import tensorflow as tf\n",
        "from plotnine import *\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression # Linear Regression Model\n",
        "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
        "\n",
        "from sklearn.model_selection import train_test_split # simple TT split cv\n",
        "from sklearn.model_selection import KFold # k-fold cv\n",
        "from sklearn.model_selection import LeaveOneOut #LOO cv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFEMsWTaxlmH"
      },
      "source": [
        "# 0. Together\n",
        "\n",
        "Neural Networks are great. Their flexibility (layers...connections...activation functions...and more!) allows you to build complex models that can accurately model complex relationships between predictors and outcomes. But Neural Networks aren't magic, if you're going to use NN's, make sure they're the right tool for your problem.\n",
        "\n",
        "\n",
        "When building a neural network you need to think about 2 (main) things:\n",
        "\n",
        "1. The Structure of the model (nodes/connections/activation functions)\n",
        "2. The Loss Function (how do we measure how well our model is doing?)\n",
        "\n",
        "\n",
        "# 1. Building a Simple NN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCDvGO8ExlmI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ywen2021/CPSC392/main/Data/Music_data.csv\")\n",
        "feats = [\"danceability\", \"energy\", \"loudness\",\"acousticness\"]\n",
        "predict = \"valence\"\n",
        "\n",
        "print(df.shape)\n",
        "X = df[feats]\n",
        "y = df[predict]\n",
        "\n",
        "z = StandardScaler()\n",
        "\n",
        "X = z.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lk4hpZ8xlmI"
      },
      "source": [
        "the model below has the same shape as a simple linear regression, like we talked about in lecture. It has an input layer with 4 inputs (\"danceability\", \"energy\", \"loudness\",\"acousticness\"), and 1 output layer for \"valence\".\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16JR3yX1gs7oC1isJAaJixNkrnZmdOxn1\" width = 800px />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaykXdsLxlmI"
      },
      "outputs": [],
      "source": [
        "# Regression\n",
        "\n",
        "#structure of the model\n",
        "model = kb.Sequential([\n",
        "    kb.layers.Dense(1, input_shape =[4]), #input\n",
        "])\n",
        "\n",
        "#how to train the model\n",
        "model.compile(loss = \"mean_squared_error\",\n",
        "              optimizer = kb.optimizers.SGD())\n",
        "\n",
        "#fit the model (same as SKlearn)\n",
        "model.fit(X,y, epochs = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t13iL7axlmJ"
      },
      "outputs": [],
      "source": [
        "# build a linear regression model using LinearRegression and fitting on X and y (no need for model validation here)\n",
        "\n",
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDuC7K0ZxlmJ"
      },
      "outputs": [],
      "source": [
        "# get weights from Neural Network\n",
        "model.get_weights()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8Wgw4EvxlmJ"
      },
      "outputs": [],
      "source": [
        "# get the coef_ and intercept_ from your linear regression model\n",
        "\n",
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT0LLkN_xlmK"
      },
      "source": [
        "### *Question*\n",
        "What happens to the weights from our neural net as you **increase** the number of epochs (compare to the coefs from the linear regression model)?\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQSX8WKkxlmK"
      },
      "source": [
        "# 2. Parameter Bloat\n",
        "\n",
        "Remember that a densely connected layer (`Dense()` in keras) is connected to EVERY node in the layer before and after it. The parameters can add up QUICKLY. Looking at the image of a densely connected, deep neural network below, try to calculate how many parameters (weights + bias) need to be estimates for that neural network (it's okay if you're off by a litte).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=19mh5qaqStcZzxir6fSWHkaiEtwMiVIVT\" width = 600px />\n",
        "\n",
        "### *Question*\n",
        "\n",
        "What do you think can happen when you have a ton of parameters and only a little data?\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />\n",
        "\n",
        "\n",
        "# 3. Building a Deep Neural Net\n",
        "\n",
        "Run the following model on the dataset `nn`. You can use `nn_test` as the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADrqeVojxlmK"
      },
      "outputs": [],
      "source": [
        "nn = pd.read_csv(\"https://raw.githubusercontent.com/ywen2021/CPSC392/main/Data/NN.csv\")\n",
        "nn_test = pd.read_csv(\"https://raw.githubusercontent.com/ywen2021/CPSC392/main/Data/NN_test.csv\")\n",
        "\n",
        "X = nn[[\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]]\n",
        "y = nn[[\"V10\"]]\n",
        "\n",
        "X_test = nn_test[[\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]]\n",
        "y_test = nn_test[[\"V10\"]]\n",
        "\n",
        "\n",
        "print(nn.shape, nn_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iarBrd6hxlmK"
      },
      "source": [
        "Build a Model with layers with 9,7,5,3,2,1 nodes respectively. Fill in the appropriate numbers to relace the `???`s. I've done the 9 and 7 for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V2qL44LxlmL"
      },
      "outputs": [],
      "source": [
        "## DEEP MODEL\n",
        "#structure of the model\n",
        "model2 = kb.Sequential([\n",
        "    kb.layers.Dense(7, input_shape =[9]), #input\n",
        "    kb.layers.Dense(???),\n",
        "    kb.layers.Dense(???),\n",
        "    kb.layers.Dense(???),\n",
        "    kb.layers.Dense(???) #output\n",
        "])\n",
        "#how to train the model\n",
        "model2.compile(loss = \"mean_squared_error\",\n",
        "              optimizer = kb.optimizers.SGD())\n",
        "\n",
        "#fit the model (same as SKlearn)\n",
        "model2.fit(X,y, epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9SLW3wFxlmL"
      },
      "source": [
        "Now use `nn` and `nn_test`, and calculate the train and test MSEs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TxGkyozxlmL"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4NZ3DQ7xlmL"
      },
      "source": [
        "# Other Random NN Topics That are Cool\n",
        "* Deep Neural Networks (NN's that have 2+ hidden layers)\n",
        "* Dropout (a way to regularize NNs)\n",
        "* Double Descent (You won't believe what this means for bias/variance tradedoff!!!)\n",
        "* Autoencoders (NN's that do non-linear PCA)\n",
        "* Generative Adversarial Networks (GANs; builds a model that can generate fake data, like faces, or paintings)\n",
        "* Recurrent Neural Networks (used for time series like sentences, music, stocks...even[harry potter](https://www.digitaltrends.com/cool-tech/harry-potter-ai-story/))\n",
        "* StyleGAN\n",
        "* Convolutional Neural Networks (often used for images, or other spatial data)\n",
        "* Shap values (a way to estimate the effect of different predictors in the NN)\n",
        "\n",
        "Check out [this video](https://www.youtube.com/watch?v=JBlm4wnjNMY), she talks big picture about what Neural Networks are and how they work\n"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}